{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b5de6e-0be9-4841-b080-df512ab68e01",
   "metadata": {},
   "source": [
    "# ü§ñ Comparison of Outputs Between Different Generative AI Models\n",
    "\n",
    "## üß† Introduction\n",
    "\n",
    "Generative AI models like GPT-4, Claude, Gemini, and others have demonstrated impressive capabilities in generating human-like text across various domains. As their usage becomes more widespread, it becomes essential to evaluate and compare the quality of their outputs in a structured manner.\n",
    "\n",
    "This notebook provides a framework for comparing outputs from multiple Generative AI models on the same set of prompts. It is designed to help users understand how different models perform across tasks like summarization, question answering, translation, and creative writing.\n",
    "\n",
    "## ‚ùì Problem Statement\n",
    "\n",
    "With the proliferation of Generative AI models, users and organizations often face the challenge of selecting the right model for their specific needs. However, this process is complicated by several factors:\n",
    "\n",
    "- ‚öñÔ∏è **Lack of standardized evaluation**: There is no uniform method to benchmark model outputs on the same tasks.\n",
    "- ü§î **Subjectivity in response quality**: Human judgments about quality can vary, making comparisons inconsistent.\n",
    "- üìä **Need for data-driven insights**: A systematic approach is required to assess and compare model performance using both qualitative and quantitative analysis.\n",
    "\n",
    "This project addresses these challenges by:\n",
    "\n",
    "- Running a fixed set of prompts across various Gen AI models.\n",
    "- Structuring and displaying their responses side-by-side.\n",
    "- Enabling both visual and manual inspection to highlight differences in tone, accuracy, fluency, and relevance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737516e6-b62d-4ad3-9f36-8132b8a2a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown,display,update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7fdf4d-1ee6-442e-9362-7fcf35dd7035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override = True)\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4226ac72-c36f-4705-8f51-0a6d168423b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url = 'http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5667bb78-451e-4764-9aaf-d71736d4248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78937391-c140-4b4f-9ab8-80444aed30cd",
   "metadata": {},
   "source": [
    "### Asking LLMs to tell a joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1992cc5e-3126-4bae-bdb1-21e426caf1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ae3fb9-3a8e-4f9a-a18c-204860ec8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9353e516-20d7-4b6c-87b6-47829f06a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "(pause for dramatic effect)\n",
      "\n",
      "Because she was always trying to fit him into a linear regression model, and he just couldn't predict their future together! (ba-dum-tss!)\n",
      "\n",
      "I hope that one wasn't too \" statistically\" inaccurate!\n",
      "\n",
      "(Sorry, I couldn't resist adding a few data-filled puns!)\n"
     ]
    }
   ],
   "source": [
    "llama = openai.chat.completions.create(\n",
    "    model=\"llama3.2\", \n",
    "    messages=prompts\n",
    ")\n",
    "\n",
    "print(llama.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94796614-4719-421c-821f-cb08e5eb91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonet = claude.messages.create(\n",
    "    model = \"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens = 20000,\n",
    "    system = system_message,\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718b4301-a166-4e36-af64-c51b77a61a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to play hide and seek?\n",
      "\n",
      "Because good luck trying to hide when they've already predicted where you'll be with 99.7% confidence!\n"
     ]
    }
   ],
   "source": [
    "print(sonet.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06c0d97-d615-43e0-ab15-53265c408fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with higher temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d00c319-c390-4169-8469-275ebb8a1468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the regression analyst break up with his girlfriend?\n",
      "\n",
      "*pauses for dramatic effect*\n",
      "\n",
      "Because he was trying to optimize their relationship, but it was just not adding value!\n",
      "\n",
      "(gets some chuckles from the data-sciency crowd)\n",
      "\n",
      "But seriously, folks, who needs emotions when you've got R-squared and RMSE?\n"
     ]
    }
   ],
   "source": [
    "llama = openai.chat.completions.create(\n",
    "    model=\"llama3.2\", \n",
    "    messages=prompts,\n",
    "    temperature = 1\n",
    ")\n",
    "\n",
    "print(llama.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bea9e4a-1313-49a6-86a5-c427c869e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonet = claude.messages.create(\n",
    "    model = \"claude-3-7-sonnet-latest\",\n",
    "    max_tokens = 20000,\n",
    "    system = system_message,\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    temperature = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4227d7f8-c401-4bcc-907f-c74bb666e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to go outside during winter?\n",
      "\n",
      "Because they're afraid of getting caught in a random forest!\n",
      "\n",
      "*ba-dum-tss* ü•Å\n"
     ]
    }
   ],
   "source": [
    "print(sonet.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089ce90-a519-49d5-8734-2fdd71dd1106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bfaaf39-6fe5-4d58-8e33-7a6cb4a3c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonet = claude.messages.create(\n",
    "    model = \"claude-3-5-sonnet-latest\",\n",
    "    max_tokens = 8000,\n",
    "    system = system_message,\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    temperature = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910786ff-1a58-4ecb-ba54-c24e7c4cd733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one for the data scientists:\n",
      "\n",
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the data was skewed and needed to be normalized at a higher level! \n",
      "\n",
      "Alternative joke:\n",
      "\n",
      "What's a data scientist's favorite kind of music?\n",
      "Algorithm and blues! \n",
      "\n",
      "*ba dum tss* üòÑ\n",
      "\n",
      "These are pretty nerdy but should get a chuckle from your data science colleagues!\n"
     ]
    }
   ],
   "source": [
    "print(sonet.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9153f66-d7be-454b-b08d-65ad10eabfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one for the data scientists:\n",
      "\n",
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the data was skewed and needed to be normalized!\n",
      "\n",
      "Alternative data science jokes:\n",
      "\n",
      "Why do data scientists make great partners?\n",
      "Because they know the importance of a good correlation!\n",
      "\n",
      "What's a data scientist's favorite snack?\n",
      "Chocolate chips and cookies... but mostly just the data chips!\n",
      "\n",
      "What did the data scientist say when they got locked out of their house?\n",
      "\"Time to use my k-nearest neighbors algorithm!\""
     ]
    }
   ],
   "source": [
    "sonet = claude.messages.stream(\n",
    "    model = \"claude-3-5-sonnet-latest\",\n",
    "    max_tokens = 8000,\n",
    "    system = system_message,\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    temperature = 1\n",
    ")\n",
    "\n",
    "with sonet as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text,end = \"\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf53e96d-0820-4657-8f54-9556d19c8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek API Key exists and begins sk-\n"
     ]
    }
   ],
   "source": [
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7e35c0-f940-42bb-b25b-e505abd5f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(base_url = \"https://api.deepseek.com\",api_key = deepseek_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d7a2070-739a-42ac-a21f-f07abe9c049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a light-hearted joke for data scientists:\n",
      "\n",
      "**Why did the data scientist bring a ladder to the bar?**  \n",
      "\n",
      "Because they heard the drinks were *high-dimensional*!  \n",
      "\n",
      "(And they wanted to reduce the dimensions before overfitting their liver!)  \n",
      "\n",
      "Hope that gives you a chuckle! üòÑ\n"
     ]
    }
   ],
   "source": [
    "res = deepseek.chat.completions.create(\n",
    "    model = \"deepseek-chat\",\n",
    "    messages = prompts,\n",
    ")\n",
    "\n",
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "728a55e0-fcf4-47ce-ad54-ce024890a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "             {\"role\": \"user\", \"content\": \"How many words are there in your answer to this prompt\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4981f62d-79fc-4530-a44d-7bf43c720b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alright, let's tackle this interesting question: \"How many words are there in your answer to this prompt.\" At first glance, it seems straightforward, but when I think deeper, it's a bit of a paradox or a self-referential problem. Here's how I'm going to approach it:\n",
       "\n",
       "### Understanding the Question\n",
       "\n",
       "The question is asking for the word count of the very answer that I'm about to provide. This creates a loop because the length of my answer depends on the number it's trying to report. \n",
       "\n",
       "For example, if I say, \"This answer contains 5 words,\" but that sentence itself is 5 words, then it's accurate. But if I say, \"This answer contains 10 words,\" and that statement is only 6 words, then it's incorrect. \n",
       "\n",
       "This seems similar to the \"This statement is false\" paradox, where the statement can't consistently be labeled as true or false without causing a contradiction.\n",
       "\n",
       "### Attempting a Simple Answer\n",
       "\n",
       "Let me try to construct a simple answer and see if it works.\n",
       "\n",
       "**Attempt 1:**\n",
       "\"This answer contains 5 words.\"\n",
       "\n",
       "Now, let's count the words in that sentence:\n",
       "1. This\n",
       "2. answer\n",
       "3. contains\n",
       "4. 5\n",
       "5. words.\n",
       "\n",
       "Yes, that's 5 words. So, this seems correct.\n",
       "\n",
       "But is this the only possible correct answer? Let me try another number.\n",
       "\n",
       "**Attempt 2:**\n",
       "\"This answer contains 7 words.\"\n",
       "\n",
       "Counting:\n",
       "1. This\n",
       "2. answer\n",
       "3. contains\n",
       "4. 7\n",
       "5. words.\n",
       "\n",
       "That's 5 words, not 7. So, this is incorrect.\n",
       "\n",
       "**Attempt 3:**\n",
       "\"The number of words in this answer is five.\"\n",
       "\n",
       "Counting:\n",
       "1. The\n",
       "2. number\n",
       "3. of\n",
       "4. words\n",
       "5. in\n",
       "6. this\n",
       "7. answer\n",
       "8. is\n",
       "9. five.\n",
       "\n",
       "That's 9 words, but I claimed it's five, which is wrong.\n",
       "\n",
       "From these attempts, it seems that only specific phrasings where the declared word count matches the actual word count will be correct.\n",
       "\n",
       "### Exploring Possible Correct Answers\n",
       "\n",
       "Is \"This answer contains 5 words.\" the only correct answer? Let me see if there are others.\n",
       "\n",
       "**Alternative Phrasing:**\n",
       "\"Here are five words in this answer.\"\n",
       "\n",
       "Counting:\n",
       "1. Here\n",
       "2. are\n",
       "3. five\n",
       "4. words\n",
       "5. in\n",
       "6. this\n",
       "7. answer.\n",
       "\n",
       "That's 7 words, but it says five, so incorrect.\n",
       "\n",
       "**Another Try:**\n",
       "\"Five words are here now.\"\n",
       "\n",
       "Counting:\n",
       "1. Five\n",
       "2. words\n",
       "3. are\n",
       "4. here\n",
       "5. now.\n",
       "\n",
       "That's 5 words, and it says five, so correct.\n",
       "\n",
       "So, \"Five words are here now.\" is also a correct answer with 5 words.\n",
       "\n",
       "Are there other numbers that could work? Let's try with 4 words.\n",
       "\n",
       "**Attempt for 4 words:**\n",
       "\"This has four words.\"\n",
       "\n",
       "Counting:\n",
       "1. This\n",
       "2. has\n",
       "3. four\n",
       "4. words.\n",
       "\n",
       "That's 4 words, correct.\n",
       "\n",
       "Similarly, \"Four words are here.\" is also 4 words.\n",
       "\n",
       "What about 3 words?\n",
       "\n",
       "\"Three words here.\"\n",
       "\n",
       "Counting:\n",
       "1. Three\n",
       "2. words\n",
       "3. here.\n",
       "\n",
       "Yes, 3 words.\n",
       "\n",
       "\"Here's three words.\" is also 3 words.\n",
       "\n",
       "2 words?\n",
       "\n",
       "\"Two words.\"\n",
       "\n",
       "Counting:\n",
       "1. Two\n",
       "2. words.\n",
       "\n",
       "Yes, 2 words.\n",
       "\n",
       "\"Only two.\" is also 2 words.\n",
       "\n",
       "1 word?\n",
       "\n",
       "\"One.\"\n",
       "\n",
       "Counting: \"One\" is 1 word.\n",
       "\n",
       "\"Word.\" is also 1 word if we're counting that as the answer.\n",
       "\n",
       "0 words? That would be an empty answer, which doesn't make sense in this context because the answer must convey the count.\n",
       "\n",
       "So, possible correct answers are those where the number declared matches the actual word count of the declaration. This seems to work for any positive integer, but the phrasing becomes more constrained as the number decreases.\n",
       "\n",
       "### Verifying with Longer Answers\n",
       "\n",
       "Can we have a correct answer with more words? Let's try 10 words.\n",
       "\n",
       "**Attempt for 10 words:**\n",
       "\"This particular answer contains exactly ten words in total here now.\"\n",
       "\n",
       "Counting:\n",
       "1. This\n",
       "2. particular\n",
       "3. answer\n",
       "4. contains\n",
       "5. exactly\n",
       "6. ten\n",
       "7. words\n",
       "8. in\n",
       "9. total\n",
       "10. here\n",
       "11. now.\n",
       "\n",
       "Oops, that's 11 words. Let me adjust.\n",
       "\n",
       "\"This answer right here contains exactly ten words in total now.\"\n",
       "\n",
       "Counting:\n",
       "1. This\n",
       "2. answer\n",
       "3. right\n",
       "4. here\n",
       "5. contains\n",
       "6. exactly\n",
       "7. ten\n",
       "8. words\n",
       "9. in\n",
       "10. total\n",
       "11. now.\n",
       "\n",
       "Still 11. Maybe:\n",
       "\n",
       "\"The total number of words in this answer is exactly ten words.\"\n",
       "\n",
       "Counting:\n",
       "1. The\n",
       "2. total\n",
       "3. number\n",
       "4. of\n",
       "5. words\n",
       "6. in\n",
       "7. this\n",
       "8. answer\n",
       "9. is\n",
       "10. exactly\n",
       "11. ten\n",
       "12. words.\n",
       "\n",
       "12 words. It's tricky to phrase a 10-word answer that correctly states it has 10 words without going over or under.\n",
       "\n",
       "Perhaps: \"This answer contains a total of ten words within this sentence here.\"\n",
       "\n",
       "Counting:\n",
       "1. This\n",
       "2. answer\n",
       "3. contains\n",
       "4. a\n",
       "5. total\n",
       "6. of\n",
       "7. ten\n",
       "8. words\n",
       "9. within\n",
       "10. this\n",
       "11. sentence\n",
       "12. here.\n",
       "\n",
       "Still 12. It seems harder to construct longer correct answers because the statement about the word count itself takes up words, making it easy to overshoot.\n",
       "\n",
       "### Conclusion on Possible Correct Answers\n",
       "\n",
       "From these trials, it appears that shorter answers where the word count declaration is concise are easier to construct correctly. Longer answers require more words to describe the count, often leading to a mismatch between the declared and actual word counts.\n",
       "\n",
       "Therefore, the correct answers are those self-referential sentences where the number of words stated equals the actual number of words in the sentence. Examples include:\n",
       "\n",
       "- \"One.\" (1 word)\n",
       "- \"Two words.\" (2 words)\n",
       "- \"This has three words.\" (3 words)\n",
       "- \"Four words are here now.\" (4 words)\n",
       "- \"This answer contains five words.\" (5 words)\n",
       "\n",
       "And so on, with the feasibility decreasing as the number increases due to the increasing word count needed to state the number.\n",
       "\n",
       "### Final Answer\n",
       "\n",
       "After exploring various possibilities, the correct answers are those where the statement about the word count accurately matches the actual number of words in that statement. Here's one such correct answer:\n",
       "\n",
       "\"This answer contains five words.\"\n",
       "\n",
       "Indeed, counting the words:\n",
       "1. This\n",
       "2. answer\n",
       "3. contains\n",
       "4. five\n",
       "5. words.\n",
       "\n",
       "So, the number of words in this answer is **five**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 800\n"
     ]
    }
   ],
   "source": [
    "res = deepseek.chat.completions.create(\n",
    "    model = \"deepseek-chat\",\n",
    "    messages = challenge,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"),display_id = True)\n",
    "for chunk in res:\n",
    "    #print(chunk)\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply),display_id = display_handle.display_id)\n",
    "\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "659d76dc-e34f-477a-88b3-f06e3e2bb2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user is asking how many words are in my response to their prompt. Let me start by understanding exactly what they need. They want the word count of the answer I'm about to give.\n",
      "\n",
      "First, I need to figure out how to approach this. I should provide the answer, then count the words in that answer. But wait, the answer includes both the explanation and the word count itself. That could complicate things because the word count part might affect the total.\n",
      "\n",
      "Let me structure my response. I'll start by addressing the question, explain the process, give the count, and then maybe confirm it. But I have to make sure that when I count the words, I include every single word in my response, including any meta-commentary about the counting.\n",
      "\n",
      "Alternatively, maybe I should write the answer first, then count the words, and then present the number. But the user is asking for the word count of the answer to this prompt, which includes everything I write here. So I need to ensure that my entire response, including the final count statement, is included in the word count.\n",
      "\n",
      "Wait, there's a possible loop here. If I state the word count, that statement adds to the total. So I need to calculate the word count of the entire response, including the part where I say \"There are X words in this answer.\" But how can I do that accurately?\n",
      "\n",
      "Let me outline the steps:\n",
      "\n",
      "1. Compose the answer to the user's question.\n",
      "2. Count all the words in that answer.\n",
      "3. Present the count as part of the answer.\n",
      "4. Ensure that the count includes the entire text, including the count statement itself.\n",
      "\n",
      "To avoid errors, maybe I can write the response, then count the words, and then insert the number. But since I can't process it after writing in real-time, I need to estimate or use a method to calculate it.\n",
      "\n",
      "Alternatively, I can use a placeholder, count the words without the placeholder, calculate how many words the placeholder would take, then adjust. For example, if the response without the count statement is N words, and the count statement is \"There are X words in this answer,\" which is 7 words plus the number. But numbers as digits don't count as words. So if X is a number like 50, the statement is 7 words. So total words would be N + 7.\n",
      "\n",
      "But how do I compute N? Let's try to draft the response.\n",
      "\n",
      "First part: The user asks for the word count. I need to explain that I will provide the count and that it includes this explanation. So the response might be something like:\n",
      "\n",
      "\"I will first provide an answer to your question and then include the word count at the end. [Explanation...] The total number of words in this response is X.\"\n",
      "\n",
      "Wait, but if I structure it that way, the X is part of the sentence. Let me try to write a sample answer to see how many words it would be.\n",
      "\n",
      "Sample answer:\n",
      "\n",
      "\"The number of words in my answer to this prompt is calculated by including every word in this response. After composing the explanation, I count each word to ensure accuracy. This sentence is part of the total count. There are X words in this answer.\"\n",
      "\n",
      "Now, let's count the words in that sample. Each word separated by a space is a word. Let's break it down:\n",
      "\n",
      "1. The\n",
      "2. number\n",
      "3. of\n",
      "4. words\n",
      "5. in\n",
      "6. my\n",
      "7. answer\n",
      "8. to\n",
      "9. this\n",
      "10. prompt\n",
      "11. is\n",
      "12. calculated\n",
      "13. by\n",
      "14. including\n",
      "15. every\n",
      "16. word\n",
      "17. in\n",
      "18. this\n",
      "19. response.\n",
      "20. After\n",
      "21. composing\n",
      "22. the\n",
      "23. explanation,\n",
      "24. I\n",
      "25. count\n",
      "26. each\n",
      "27. word\n",
      "28. to\n",
      "29. ensure\n",
      "30. accuracy.\n",
      "31. This\n",
      "32. sentence\n",
      "33. is\n",
      "34. part\n",
      "35. of\n",
      "36. the\n",
      "37. total\n",
      "38. count.\n",
      "39. There\n",
      "40. are\n",
      "41. X\n",
      "42. words\n",
      "43. in\n",
      "44. this\n",
      "45. answer.\n",
      "\n",
      "That's 45 words, with X being a placeholder. But in reality, X would be a number, which is written as a word or a numeral? If it's a numeral (e.g., 45), does that count as a word? Typically, numerals are considered as one word if they're written as a single token. So \"45\" is one word. So the sample above has 45 words. Wait, but in the sample, the first sentence has 19 words up to \"response.\" Then the next sentences add up. Let me recount:\n",
      "\n",
      "First sentence: \"The number of words in my answer to this prompt is calculated by including every word in this response.\" ‚Äì 19 words.\n",
      "\n",
      "Second sentence: \"After composing the explanation, I count each word to ensure accuracy.\" ‚Äì 12 words.\n",
      "\n",
      "Third sentence: \"This sentence is part of the total count.\" ‚Äì 8 words.\n",
      "\n",
      "Fourth sentence: \"There are X words in this answer.\" ‚Äì 7 words (with X as 1 word).\n",
      "\n",
      "Total: 19 + 12 + 8 + 7 = 46 words. Wait, maybe I miscounted. Let's check each sentence:\n",
      "\n",
      "First sentence breakdown:\n",
      "\n",
      "1. The\n",
      "2. number\n",
      "3. of\n",
      "4. words\n",
      "5. in\n",
      "6. my\n",
      "7. answer\n",
      "8. to\n",
      "9. this\n",
      "10. prompt\n",
      "11. is\n",
      "12. calculated\n",
      "13. by\n",
      "14. including\n",
      "15. every\n",
      "16. word\n",
      "17. in\n",
      "18. this\n",
      "19. response.\n",
      "\n",
      "Yes, 19 words.\n",
      "\n",
      "Second sentence:\n",
      "\n",
      "20. After\n",
      "21. composing\n",
      "22. the\n",
      "23. explanation,\n",
      "24. I\n",
      "25. count\n",
      "26. each\n",
      "27. word\n",
      "28. to\n",
      "29. ensure\n",
      "30. accuracy.\n",
      "\n",
      "That's 11 words (20-30), but wait, numbers 20-30 is 11 items. So 11 words.\n",
      "\n",
      "Third sentence:\n",
      "\n",
      "31. This\n",
      "32. sentence\n",
      "33. is\n",
      "34. part\n",
      "35. of\n",
      "36. the\n",
      "37. total\n",
      "38. count.\n",
      "\n",
      "8 words (31-38).\n",
      "\n",
      "Fourth sentence:\n",
      "\n",
      "39. There\n",
      "40. are\n",
      "41. X\n",
      "42. words\n",
      "43. in\n",
      "44. this\n",
      "45. answer.\n",
      "\n",
      "7 words (39-45).\n",
      "\n",
      "Total: 19 + 11 + 8 +7 = 45 words. But the count in the fourth sentence is X, which is a placeholder. If X is a numeral like 45, then that's one word. So total words would be 45. But the actual answer's word count would depend on the exact number. However, this is a sample. The actual answer needs to be written, then the count done.\n",
      "\n",
      "But this approach might not be feasible because I can't precompute the exact number without knowing the exact response. Therefore, perhaps the best way is to write the answer, then count the words as I write, including the final count statement.\n",
      "\n",
      "Alternatively, perhaps the assistant's response would be something concise. Let's try.\n",
      "\n",
      "User's question: \"How many words are there in your answer to this prompt\"\n",
      "\n",
      "Assistant's response:\n",
      "\n",
      "To determine the word count of this response, I will provide the answer here: The total number of words in this answer is [X]. When calculating, every word, including those in this sentence, is counted.\n",
      "\n",
      "Now, let's count the words in that response.\n",
      "\n",
      "Breaking it down:\n",
      "\n",
      "1. To\n",
      "2. determine\n",
      "3. the\n",
      "4. word\n",
      "5. count\n",
      "6. of\n",
      "7. this\n",
      "8. response,\n",
      "9. I\n",
      "10. will\n",
      "11. provide\n",
      "12. the\n",
      "13. answer\n",
      "14. here:\n",
      "15. The\n",
      "16. total\n",
      "17. number\n",
      "18. of\n",
      "19. words\n",
      "20. in\n",
      "21. this\n",
      "22. answer\n",
      "23. is\n",
      "24. [X].\n",
      "25. When\n",
      "26. calculating,\n",
      "27. every\n",
      "28. word,\n",
      "29. including\n",
      "30. those\n",
      "31. in\n",
      "32. this\n",
      "33. sentence,\n",
      "34. is\n",
      "35. counted.\n",
      "\n",
      "That's 35 words. But [X] is a placeholder. If [X] is replaced with the actual number, say 35, then \"35\" is one word. So the total words would be 35. However, the sentence would then be:\n",
      "\n",
      "\"The total number of words in this answer is 35. When calculating, every word, including those in this sentence, is counted.\"\n",
      "\n",
      "But let's recount with the number:\n",
      "\n",
      "1. To\n",
      "2. determine\n",
      "3. the\n",
      "4. word\n",
      "5. count\n",
      "6. of\n",
      "7. this\n",
      "8. response,\n",
      "9. I\n",
      "10. will\n",
      "11. provide\n",
      "12. the\n",
      "13. answer\n",
      "14. here:\n",
      "15. The\n",
      "16. total\n",
      "17. number\n",
      "18. of\n",
      "19. words\n",
      "20. in\n",
      "21. this\n",
      "22. answer\n",
      "23. is\n",
      "24. 35.\n",
      "25. When\n",
      "26. calculating,\n",
      "27. every\n",
      "28. word,\n",
      "29. including\n",
      "30. those\n",
      "31. in\n",
      "32. this\n",
      "33. sentence,\n",
      "34. is\n",
      "35. counted.\n",
      "\n",
      "That's 35 words. But wait, inserting \"35\" as the 24th word, the count becomes 35 words. But the statement claims there are 35 words. However, if the total is indeed 35, then the count is correct. But when I wrote the response, the placeholder [X] is replaced by 35, making the total 35 words. However, if the actual count is different, the number would change.\n",
      "\n",
      "This creates a paradox because the count is part of the response. To resolve this, the assistant must craft a response where the declared word count accurately reflects the total words, including the count itself.\n",
      "\n",
      "Therefore, the assistant needs to construct a response where the total number of words, when including the count statement, equals the number stated. For example, if the response is exactly 30 words, then the count statement should say 30, and the entire response, including that statement, must be 30 words.\n",
      "\n",
      "Let me try to construct such a response.\n",
      "\n",
      "Example 1:\n",
      "\n",
      "\"This response contains exactly ten words plus the number stated here: 16.\"\n",
      "\n",
      "Wait, let's count:\n",
      "\n",
      "1. This\n",
      "2. response\n",
      "3. contains\n",
      "4. exactly\n",
      "5. ten\n",
      "6. words\n",
      "7. plus\n",
      "8. the\n",
      "9. number\n",
      "10. stated\n",
      "11. here:\n",
      "12. 16.\n",
      "\n",
      "That's 12 words, but the number claimed is 16. Doesn't match.\n",
      "\n",
      "Example 2:\n",
      "\n",
      "\"The word count of this answer is 14 words in total.\"\n",
      "\n",
      "Count:\n",
      "\n",
      "1. The\n",
      "2. word\n",
      "3. count\n",
      "4. of\n",
      "5. this\n",
      "6. answer\n",
      "7. is\n",
      "8. 14\n",
      "9. words\n",
      "10. in\n",
      "11. total.\n",
      "\n",
      "That's 11 words, but the count says 14. Not correct.\n",
      "\n",
      "This is tricky. Maybe a better approach is to write the response, count the words, and then adjust the count statement to make the total correct. Let's try:\n",
      "\n",
      "Draft response:\n",
      "\n",
      "\"The number of words in this answer is X. This sentence ensures the total count is accurate.\"\n",
      "\n",
      "Now, let's count the words without X:\n",
      "\n",
      "1. The\n",
      "2. number\n",
      "3. of\n",
      "4. words\n",
      "5. in\n",
      "6. this\n",
      "7. answer\n",
      "8. is\n",
      "9. X.\n",
      "10. This\n",
      "11. sentence\n",
      "12. ensures\n",
      "13. the\n",
      "14. total\n",
      "15. count\n",
      "16. is\n",
      "17. accurate.\n",
      "\n",
      "That's 17 words. If X is 17, then the sentence becomes:\n",
      "\n",
      "\"The number of words in this answer is 17. This sentence ensures the total count is accurate.\"\n",
      "\n",
      "Now count again:\n",
      "\n",
      "1. The\n",
      "2. number\n",
      "3. of\n",
      "4. words\n",
      "5. in\n",
      "6. this\n",
      "7. answer\n",
      "8. is\n",
      "9. 17.\n",
      "10. This\n",
      "11. sentence\n",
      "12. ensures\n",
      "13. the\n",
      "14. total\n",
      "15. count\n",
      "16. is\n",
      "17. accurate.\n",
      "\n",
      "Yes, 17 words. So X=17. Therefore, this response correctly states that it has 17 words. But in reality, the count is correct. Therefore, this method works.\n",
      "\n",
      "Applying this to the original problem. The user is asking for the word count of the assistant's answer. The assistant needs to craft a response where the declared count is accurate, including the count statement itself.\n",
      "\n",
      "Therefore, the assistant can construct a two-sentence response where the first sentence states the count, and the second sentence is there to adjust the total word count to match the stated number.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"The number of words in this answer is fifteen. This sentence adjusts the count to fifteen.\"\n",
      "\n",
      "Let's count:\n",
      "\n",
      "1. The\n",
      "2. number\n",
      "3. of\n",
      "4. words\n",
      "5. in\n",
      "6. this\n",
      "7. answer\n",
      "8. is\n",
      "9. fifteen.\n",
      "10. This\n",
      "11. sentence\n",
      "12. adjusts\n",
      "13. the\n",
      "14. count\n",
      "15. to\n",
      "16. fifteen.\n",
      "\n",
      "Wait, that's 16 words, but the count says fifteen (15). Doesn't match. So this approach is flawed.\n",
      "\n",
      "Alternatively:\n",
      "\n",
      "\"There are X words in this response.\" Let's make X=6.\n",
      "\n",
      "1. There\n",
      "2. are\n",
      "3. 6\n",
      "4. words\n",
      "5. in\n",
      "6. this\n",
      "7. response.\n",
      "\n",
      "That's 7 words, but X is 6. Not matching.\n",
      "\n",
      "Another try:\n",
      "\n",
      "\"This response contains exactly seven words.\" Count: 1-7. Yes, correct.\n",
      "\n",
      "But if the response is \"This response contains exactly seven words.\", which is 7 words. That works. But in this case, the user's question is about the assistant's answer. So if the assistant responds with that sentence, it's 7 words, and the count is accurate.\n",
      "\n",
      "But perhaps the user expects a more detailed explanation. However, the assistant can choose to respond concisely to make the count accurate.\n",
      "\n",
      "So, possible answer:\n",
      "\n",
      "\"There are exactly seven words in this response.\"\n",
      "\n",
      "Count: 1. There 2. are 3. exactly 4. seven 5. words 6. in 7. this 8. response. Wait, that's 8 words. Oops, mistake. So the statement claims seven but has eight words. Not correct.\n",
      "\n",
      "Alternatively:\n",
      "\n",
      "\"This answer has six words.\" Count: 1-6. Correct.\n",
      "\n",
      "But the sentence \"This answer has six words.\" is six words. Correct.\n",
      "\n",
      "Yes: 1. This 2. answer 3. has 4. six 5. words 6. ‚Üí six words. But the sentence is \"This answer has six words.\" which is six words. So that works.\n",
      "\n",
      "But the user's question is to provide the word count of the assistant's answer. So if the answer is \"This answer contains six words.\", which is six words, then it's accurate.\n",
      "\n",
      "However, maybe the assistant needs to provide a more elaborate answer first, then state the count. But that complicates the count because the count statement's length affects the total.\n",
      "\n",
      "Alternatively, the assistant can write the entire response, then manually count the words and adjust the count statement accordingly. Since the assistant can process text, it can calculate the exact count.\n",
      "\n",
      "In reality, when the assistant generates the response, it can count the words precisely. So the correct approach is:\n",
      "\n",
      "1. Compose the answer.\n",
      "2. Count all the words in the answer, including the part where the count is stated.\n",
      "3. Insert the correct number into the count statement.\n",
      "4. Ensure that the total count matches the stated number.\n",
      "\n",
      "For example:\n",
      "\n",
      "Answer: \"The total number of words in this response, including this statement, is 20.\"\n",
      "\n",
      "Now, count the words:\n",
      "\n",
      "1. The\n",
      "2. total\n",
      "3. number\n",
      "4. of\n",
      "5. words\n",
      "6. in\n",
      "7. this\n",
      "8. response,\n",
      "9. including\n",
      "10. this\n",
      "11. statement,\n",
      "12. is\n",
      "13. 20.\n",
      "\n",
      "That's 13 words, but the count says 20. Not correct.\n",
      "\n",
      "This method is error-prone. The only way to make it accurate is to construct the response so that the count statement's word count plus the rest of the response equals the stated number.\n",
      "\n",
      "Alternatively, use a two-part response where the first part is filler text to reach the exact count when combined with the count statement.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"To answer your question, this response contains a total of X words. Each word is counted once, including those in this explanatory sentence.\"\n",
      "\n",
      "Now, to find X:\n",
      "\n",
      "Count the words in the entire response except the X:\n",
      "\n",
      "1. To\n",
      "2. answer\n",
      "3. your\n",
      "4. question,\n",
      "5. this\n",
      "6. response\n",
      "7. contains\n",
      "8. a\n",
      "9. total\n",
      "10. of\n",
      "11. X\n",
      "12. words.\n",
      "13. Each\n",
      "14. word\n",
      "15. is\n",
      "16. counted\n",
      "17. once,\n",
      "18. including\n",
      "19. those\n",
      "20. in\n",
      "21. this\n",
      "22. explanatory\n",
      "23. sentence.\n",
      "\n",
      "That's 23 words. If X is 23, then the total becomes 23. But the sentence would be:\n",
      "\n",
      "\"To answer your question, this response contains a total of 23 words. Each word is counted once, including those in this explanatory sentence.\"\n",
      "\n",
      "Now count again:\n",
      "\n",
      "1. To\n",
      "2. answer\n",
      "3. your\n",
      "4. question,\n",
      "5. this\n",
      "6. response\n",
      "7. contains\n",
      "8. a\n",
      "9. total\n",
      "10. of\n",
      "11. 23\n",
      "12. words.\n",
      "13. Each\n",
      "14. word\n",
      "15. is\n",
      "16. counted\n",
      "17. once,\n",
      "18. including\n",
      "19. those\n",
      "20. in\n",
      "21. this\n",
      "22. explanatory\n",
      "23. sentence.\n",
      "\n",
      "That's 23 words. Perfect. So X=23.\n",
      "\n",
      "Thus, the assistant can craft a response where the count is accurate by carefully constructing the sentences to include the exact number of words stated.\n",
      "\n",
      "Applying this to the current problem, the assistant needs to generate a response where the total word count is correctly stated, including the count itself.\n",
      "\n",
      "So, the final answer would be a response that states the word count, and the total number of words in that response equals the stated count.\n",
      "To determine the word count of this response, I will provide the answer here: The total number of words in this answer is **45**. When calculating, every word, including those in this sentence, is counted.  \n",
      "\n",
      "**Word Count Verification:**  \n",
      "1. Break down the response into individual words.  \n",
      "2. Count each word, including numbers and punctuation-attached words.  \n",
      "3. Ensure the final count includes all words stated.  \n",
      "\n",
      "The stated total (**45**) accounts for every word in this entire answer.  \n",
      "\n",
      "**Final Answer:**  \n",
      "There are \\boxed{45} words in this response.\n",
      "Number of words: 92\n"
     ]
    }
   ],
   "source": [
    "response = deepseek.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    messages=challenge\n",
    ")\n",
    "\n",
    "reasoning_content = response.choices[0].message.reasoning_content\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print(reasoning_content)\n",
    "print(content)\n",
    "print(\"Number of words:\", len(content.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7026d-e30c-436f-9b01-35dac5ca56e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
